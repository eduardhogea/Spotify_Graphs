{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spotipy\n",
    "!pip install python-louvain\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy . oauth2 import SpotifyClientCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from collections import Counter\n",
    "import community as community_louvain\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = \"fe233373eb024c3a97f1eeca78dba3c8\"\n",
    "CLIENT_SECRET = \"34f0386560eb4dcb88e317f81b11b961\"\n",
    "\n",
    "auth_manager = SpotifyClientCredentials (client_id = CLIENT_ID, client_secret = CLIENT_SECRET)\n",
    "sp = spotipy . Spotify ( auth_manager = auth_manager )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_common_nodes(*arg):\n",
    "    \"\"\"\n",
    "    Return the number of common nodes between a set of graphs.\n",
    "\n",
    "    :param arg: (an undetermined number of) networkx graphs.\n",
    "    :return: an integer, number of common nodes.\n",
    "    \"\"\"\n",
    "    common_nodes = set(arg[0].nodes())\n",
    "    for g in arg[1:]:\n",
    "        common_nodes.intersection_update(set(g.nodes()))\n",
    "    return len(common_nodes)\n",
    "\n",
    "def get_degree_distribution(g: nx.Graph) -> dict:\n",
    "    \"\"\"\n",
    "    Get the degree distribution of the graph.\n",
    "\n",
    "    :param g: networkx graph.\n",
    "    :return: dictionary with degree distribution (keys are degrees, values are number of occurrences).\n",
    "    \"\"\"\n",
    "    degrees = [g.degree(n) for n in g.nodes()]\n",
    "    degree_distribution = Counter(degrees)\n",
    "    return degree_distribution\n",
    "\n",
    "def get_k_most_central(g: nx.Graph, metric: str, num_nodes: int) -> list:\n",
    "    \"\"\"\n",
    "    Get the k most central nodes in the graph.\n",
    "\n",
    "    :param g: networkx graph.\n",
    "    :param metric: centrality metric. Can be (at least) 'degree', 'betweenness', 'closeness' or 'eigenvector'.\n",
    "    :param num_nodes: number of nodes to return.\n",
    "    :return: list with the top num_nodes nodes with the specified centrality.\n",
    "    \"\"\"\n",
    "    if metric == 'degree':\n",
    "        centrality = nx.degree_centrality(g)\n",
    "    elif metric == 'betweenness':\n",
    "        centrality = nx.betweenness_centrality(g)\n",
    "    elif metric == 'closeness':\n",
    "        centrality = nx.closeness_centrality(g)\n",
    "    elif metric == 'eigenvector':\n",
    "        centrality = nx.eigenvector_centrality(g)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric: {metric}\")\n",
    "\n",
    "    sorted_centrality = sorted(centrality.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return [node for node, centrality in sorted_centrality[:num_nodes]]\n",
    "\n",
    "def find_cliques(g: nx.Graph, min_size_clique: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Find cliques in the graph g with size at least min_size_clique.\n",
    "\n",
    "    :param g: networkx graph.\n",
    "    :param min_size_clique: minimum size of the cliques to find.\n",
    "    :return: two-element tuple, list of cliques (each clique is a list of nodes) and\n",
    "        list of nodes in any of the cliques.\n",
    "    \"\"\"\n",
    "    cliques = list(nx.find_cliques(g))\n",
    "    cliques = [c for c in cliques if len(c) >= min_size_clique]\n",
    "    nodes_in_cliques = set(itertools.chain.from_iterable(cliques))\n",
    "    return cliques, list(nodes_in_cliques)\n",
    "\n",
    "def detect_communities(g: nx.Graph, method: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Detect communities in the graph g using the specified method.\n",
    "\n",
    "    :param g: a networkx graph.\n",
    "    :param method: string with the name of the method to use. Can be (at least) 'givarn-newman' or 'louvain'.\n",
    "    :return: two-element tuple, list of communities (each community is a list of nodes) and modularity of the partition.\n",
    "    \"\"\"\n",
    "    if method == 'girvan_newman':\n",
    "        communities_generator = nx.algorithms.community.girvan_newman(g)\n",
    "        top_level_communities = next(communities_generator)\n",
    "        communities = [list(c) for c in top_level_communities]\n",
    "        modularity = nx.algorithms.community.modularity(g, communities)\n",
    "    elif method == 'louvain':\n",
    "        partition = community_louvain.best_partition(g)\n",
    "        communities = list(set(partition.values()))\n",
    "        communities = [[nodes for nodes, community in partition.items() if community == com] for com in communities]\n",
    "        modularity = community_louvain.modularity(partition, g)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    return communities, modularity\n",
    "def retrieve_bidirectional_edges(g: nx.DiGraph, out_filename: str) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Convert a directed graph into an undirected graph by considering bidirectional edges only.\n",
    "\n",
    "    :param g: a networkx digraph.\n",
    "    :param out_filename: name of the file that will be saved.\n",
    "    :return: a networkx undirected graph.\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    out = nx.Graph()\n",
    "    out.add_nodes_from(g)\n",
    "\n",
    "    for edge in g.edges():  \n",
    "      if edge[::-1] in g.edges(): #check if reverse edge exist in graph\n",
    "        out.add_edge(edge[0],edge[1])\n",
    "    \n",
    "    out.remove_nodes_from(list(nx.isolates(out))) #Remove nodes without edges\n",
    "\n",
    "    nx.write_graphml(out, out_filename+\".graphml\")\n",
    "    return out\n",
    "    # ----------------- END OF FUNCTION --------------------- #\n",
    "    \n",
    "def create_similarity_graph(artist_audio_features_df: pd.DataFrame, similarity: str, out_filename: str = None) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Create a similarity graph from a dataframe with mean audio features per artist.\n",
    "\n",
    "    :param artist_audio_features_df: dataframe with mean audio features per artist.\n",
    "    :param similarity: the name of the similarity metric to use (e.g. \"cosine\" or \"euclidean\").\n",
    "    :param out_filename: name of the file that will be saved.\n",
    "    :return: a networkx graph with the similarity between artists as edge weights.\n",
    "    \"\"\"\n",
    "    complete = nx.Graph()\n",
    "\n",
    "    for index, row in artist_audio_features_df.iterrows():\n",
    "      complete.add_node(index, features=row.tolist())  # index is considered as the name/id\n",
    "\n",
    "    complete.add_edges_from(itertools.combinations(complete, 2))\n",
    "\n",
    "    for ins,out,weight in complete.edges(data=True):\n",
    "      features_in = np.array(dict(complete.nodes())[ins]['features'])  \n",
    "      features_out = np.array(dict(complete.nodes())[out]['features']) \n",
    "\n",
    "      if similarity=='euclidean':\n",
    "        dist = np.linalg.norm(features_in-features_out)\n",
    "      elif similarity=='cosine':\n",
    "        dist = dot(features_in, features_out)/(norm(features_in)*norm(features_out))\n",
    "      \n",
    "      weight['weight'] = dist \n",
    "    \n",
    "    for node in list(complete.nodes()):\n",
    "      del dict(complete.nodes())[node]['features']\n",
    "\n",
    "    if out_filename is not None:\n",
    "        nx.write_graphml(complete, out_filename+\".graphml\")\n",
    "\n",
    "    return complete  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gB = nx.read_graphml('gB.graphml')\n",
    "gD = nx.read_graphml('gD.graphml')\n",
    "fB = nx.read_graphml('fB.graphml')\n",
    "hB = nx.read_graphml('hB.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1\n",
    "gB_prime = retrieve_bidirectional_edges(gB, 'gB_bi')\n",
    "gD_prime = retrieve_bidirectional_edges(gD, 'gD_bi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common nodes between gB and fB: 27\n",
      "Number of common nodes between gB and hB: 510\n"
     ]
    }
   ],
   "source": [
    "# Number of common nodes between gB and fB\n",
    "common_nodes_gB_fB = num_common_nodes(gB, fB)\n",
    "print(\"Number of common nodes between gB and fB:\", common_nodes_gB_fB)\n",
    "\n",
    "# Number of common nodes between gB and hB\n",
    "common_nodes_gB_hB = num_common_nodes(gB, hB)\n",
    "print(\"Number of common nodes between gB and hB:\", common_nodes_gB_hB)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating similarity graphs\n",
    "\n",
    "#!!!!!!!! needs revision\n",
    "similarity_gB_fB = create_similarity_graph(gB_df, 'cosine', 'gB_fB')\n",
    "similarity_gB_hB = create_similarity_graph(hB_df, 'cosine', 'gB_hB')\n",
    "\n",
    "\n",
    "# Comparing the number of common nodes with similarity graph results\n",
    "print(\"Number of nodes in the similarity graph (gB, fB):\", similarity_gB_fB.number_of_nodes())\n",
    "print(\"Number of nodes in the similarity graph (gB, hB):\", similarity_gB_hB.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in common between degree centrality and betweenness centrality: 2\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "# Calculate the 25 most central nodes based on degree centrality\n",
    "degree_central_nodes = get_k_most_central(gB_prime, 'degree', 25)\n",
    "\n",
    "# Calculate the 25 most central nodes based on betweenness centrality\n",
    "betweenness_central_nodes = get_k_most_central(gB_prime, 'betweenness', 25)\n",
    "\n",
    "# Determine the number of nodes in common between the two sets\n",
    "common_nodes = set(degree_central_nodes) & set(betweenness_central_nodes)\n",
    "num_common_nodes = len(common_nodes)\n",
    "\n",
    "print(\"Number of nodes in common between degree centrality and betweenness centrality:\", num_common_nodes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Most Central Nodes (Degree Centrality) in gB': ['Huncho Jack', 'Yung Joc', 'Young Thug', 'Ab-Soul', 'Young Dro', 'Gorilla Zoe', 'Lil Scrappy', 'Boyz N Da Hood', 'Freddie Gibbs', 'Vince Staples', 'Quality Control', 'David Banner', 'Rich Boy', 'NAV', 'Famous Dex', 'Flipp Dinero', 'Rocko', 'Hurricane Chris', 'U.S.D.A.', 'Shawty Lo', 'PARTYNEXTDOOR', 'Gunna', 'Migos', 'A$AP Ferg', 'Jim Jones']\n",
      "25 Most Central Nodes (Betweenness Centrality) in gB': ['DJ Drama', 'Curren$y', 'A$AP Twelvyy', 'A$AP Mob', 'Jeremih', 'Kid Ink', 'Desiigner', 'Flatbush Zombies', 'Yo Gotti', 'Bobby Shmurda', 'PARTYNEXTDOOR', 'O.T. Genasis', 'K CAMP', 'Swizz Beatz', 'DeJ Loaf', 'Waka Flocka Flame', 'Max B', 'French Montana', 'Mike WiLL Made-It', 'Trinidad James', 'Jacquees', 'Huncho Jack', 'Domo Genesis', 'Eric Bellinger', 'Young Money']\n",
      "Number of Nodes in Common: 2\n",
      "Minimum Size of Cliques in gB': 7\n",
      "Number of Cliques in gB': 7\n",
      "Number of Different Nodes in All Cliques in gB': 20\n",
      "Minimum Size of Cliques in gD': 9\n",
      "Number of Cliques in gD': 6\n",
      "Number of Different Nodes in All Cliques in gD': 31\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "#Find cliques in gB' and gD' with the maximum value of min_size_clique that generates at least 2 cliques\n",
    "max_possible_size_gB = len(gB_prime.nodes())\n",
    "max_possible_size_gD = len(gD_prime.nodes())\n",
    "\n",
    "min_size_clique_gB = None\n",
    "min_size_clique_gD = None\n",
    "\n",
    "for size in range(max_possible_size_gB, 1, -1):\n",
    "    cliques_gB_prime, _ = find_cliques(gB_prime, size)\n",
    "    if len(cliques_gB_prime) >= 2:\n",
    "        min_size_clique_gB = size\n",
    "        break\n",
    "\n",
    "for size in range(max_possible_size_gD, 1, -1):\n",
    "    cliques_gD_prime, _ = find_cliques(gD_prime, size)\n",
    "    if len(cliques_gD_prime) >= 2:\n",
    "        min_size_clique_gD = size\n",
    "        break\n",
    "\n",
    "# Step 5: Calculate the total number of cliques and total number of different nodes in all cliques for gB' and gD'\n",
    "num_cliques_gB_prime = len(cliques_gB_prime)\n",
    "num_nodes_in_cliques_gB_prime = len(set(node for clique in cliques_gB_prime for node in clique))\n",
    "\n",
    "num_cliques_gD_prime = len(cliques_gD_prime)\n",
    "num_nodes_in_cliques_gD_prime = len(set(node for clique in cliques_gD_prime for node in clique))\n",
    "\n",
    "# Print the results\n",
    "print(\"25 Most Central Nodes (Degree Centrality) in gB':\", degree_central_nodes)\n",
    "print(\"25 Most Central Nodes (Betweenness Centrality) in gB':\", betweenness_central_nodes)\n",
    "print(\"Number of Nodes in Common:\", num_common_nodes)\n",
    "\n",
    "print(\"Minimum Size of Cliques in gB':\", min_size_clique_gB)\n",
    "print(\"Number of Cliques in gB':\", num_cliques_gB_prime)\n",
    "print(\"Number of Different Nodes in All Cliques in gB':\", num_nodes_in_cliques_gB_prime)\n",
    "\n",
    "print(\"Minimum Size of Cliques in gD':\", min_size_clique_gD)\n",
    "print(\"Number of Cliques in gD':\", num_cliques_gD_prime)\n",
    "print(\"Number of Different Nodes in All Cliques in gD':\", num_nodes_in_cliques_gD_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yung Joc', 'Lil Scrappy', 'Boyz N Da Hood', 'Young Dro', 'Rich Boy', 'Shawty Lo', 'U.S.D.A.']\n",
      "Artists in the largest clique:\n",
      "999       Young Dro\n",
      "1000      Young Dro\n",
      "1001      Young Dro\n",
      "1002      Young Dro\n",
      "1003      Young Dro\n",
      "           ...     \n",
      "8566    Lil Scrappy\n",
      "8567    Lil Scrappy\n",
      "8568    Lil Scrappy\n",
      "8569    Lil Scrappy\n",
      "8570    Lil Scrappy\n",
      "Name: artist_name, Length: 140, dtype: object\n",
      "\n",
      "How common is theexplicit music among the artists:\n",
      "explicit\n",
      "True     126\n",
      "False     14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "D = pd.read_csv('data_session-1.csv')\n",
    "# Find the largest clique in gB' or gD' (depending on your choice)\n",
    "largest_clique = max(nx.find_cliques(gB_prime), key=len)\n",
    "\n",
    "print(largest_clique)\n",
    "# Filter the artist DataFrame D to include only artists in the largest clique\n",
    "clique_artists = D[D['artist_name'].isin(largest_clique)]\n",
    "\n",
    "#print(clique_artists)\n",
    "# Analyze the characteristics of the artists in the clique\n",
    "common = clique_artists['explicit'].value_counts().head(5)\n",
    "\n",
    "# Print the results\n",
    "print(\"Artists in the largest clique:\")\n",
    "print(clique_artists['artist_name'])\n",
    "print()\n",
    "print(\"How common is theexplicit music among the artists:\")\n",
    "print(common)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "communities, modularity = detect_communities(gD_prime, 'louvain') # or 'girvan_newman'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Young Dro',\n",
       " 'Rocko',\n",
       " 'Yo Gotti',\n",
       " 'Young Money',\n",
       " 'Soulja Boy',\n",
       " 'Travis Porter']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 7\n",
    "nx.shortest_path(gB_prime, 'Young Dro', 'Travis Porter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
