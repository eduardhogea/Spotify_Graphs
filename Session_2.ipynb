{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CNIp1QlN_EG"
      },
      "source": [
        "###Make spotipy work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hiUEHuSTFVb4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install spotipy\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import spotipy\n",
        "from spotipy . oauth2 import SpotifyClientCredentials\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oX_qBnSQFo1C"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = \"fe233373eb024c3a97f1eeca78dba3c8\"\n",
        "CLIENT_SECRET = \"34f0386560eb4dcb88e317f81b11b961\"\n",
        "\n",
        "auth_manager = SpotifyClientCredentials (client_id = CLIENT_ID, client_secret = CLIENT_SECRET)\n",
        "sp = spotipy . Spotify ( auth_manager = auth_manager )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDizQm1fTHxp"
      },
      "source": [
        "###Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XSUVTEPCSpKW"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np\n",
        "import itertools\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# ------- IMPLEMENT HERE ANY AUXILIARY FUNCTIONS NEEDED ------- #\n",
        "\n",
        "\n",
        "# --------------- END OF AUXILIARY FUNCTIONS ------------------ #\n",
        "\n",
        "def retrieve_bidirectional_edges(g: nx.DiGraph, out_filename: str) -> nx.Graph:\n",
        "    \"\"\"\n",
        "    Convert a directed graph into an undirected graph by considering bidirectional edges only.\n",
        "\n",
        "    :param g: a networkx digraph.\n",
        "    :param out_filename: name of the file that will be saved.\n",
        "    :return: a networkx undirected graph.\n",
        "    \"\"\"\n",
        "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
        "    out = nx.Graph()\n",
        "    out.add_nodes_from(g)\n",
        "\n",
        "    for edge in g.edges():  \n",
        "      if edge[::-1] in g.edges(): #check if reverse edge exist in graph\n",
        "        out.add_edge(edge[0],edge[1])\n",
        "    \n",
        "    out.remove_nodes_from(list(nx.isolates(out))) #Remove nodes without edges\n",
        "\n",
        "    nx.write_graphml(out, out_filename+\".graphml\")\n",
        "    return out\n",
        "    # ----------------- END OF FUNCTION --------------------- #\n",
        "\n",
        "\n",
        "def prune_low_degree_nodes(g: nx.Graph, min_degree: int, out_filename: str) -> nx.Graph:\n",
        "    \"\"\"\n",
        "    Prune a graph by removing nodes with degree < min_degree.\n",
        "\n",
        "    :param g: a networkx graph.\n",
        "    :param min_degree: lower bound value for the degree.\n",
        "    :param out_filename: name of the file that will be saved.\n",
        "    :return: a pruned networkx graph.\n",
        "    \"\"\"\n",
        "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
        "    out = nx.Graph()\n",
        "    out.add_nodes_from(g)\n",
        "    out.add_edges_from(list(g.edges()))\n",
        "    \n",
        "    out.remove_nodes_from([node for node,degree in dict(out.degree()).items() if degree < min_degree])    \n",
        "    \n",
        "    out.remove_nodes_from(list(nx.isolates(out))) #Remove nodes without edges\n",
        "\n",
        "    nx.write_graphml(out, out_filename+\".graphml\")    \n",
        "    return out\n",
        "    # ----------------- END OF FUNCTION --------------------- #\n",
        "\n",
        "\n",
        "def prune_low_weight_edges(g: nx.Graph, min_weight=None, min_percentile=None, out_filename: str = None) -> nx.Graph:\n",
        "    \"\"\"\n",
        "    Prune a graph by removing edges with weight < threshold. Threshold can be specified as a value or as a percentile.\n",
        "\n",
        "    :param g: a weighted networkx graph.\n",
        "    :param min_weight: lower bound value for the weight.\n",
        "    :param min_percentile: lower bound percentile for the weight.\n",
        "    :param out_filename: name of the file that will be saved.\n",
        "    :return: a pruned networkx graph.\n",
        "    \"\"\"\n",
        "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
        "    if (min_weight==None and min_percentile==None) or not (min_weight==None or min_percentile==None):\n",
        "      raise Exception('Use only one parameter: min_weight or min_percentile')\n",
        "    \n",
        "    out = copy.deepcopy(g)  \n",
        "\n",
        "    if min_weight == None:\n",
        "      min_weight = np.percentile(np.sort(np.array([e[2] for e in out.edges.data('weight')])), min_percentile) \n",
        "\n",
        "    out.remove_edges_from(list(filter(lambda e: e[2] < min_weight, (e for e in out.edges.data('weight')))))\n",
        "    \n",
        "    out.remove_nodes_from(list(nx.isolates(out))) #Remove nodes without edges\n",
        "\n",
        "    nx.write_graphml(out, out_filename+\".graphml\")    \n",
        "    return out\n",
        "    # ----------------- END OF FUNCTION --------------------- #\n",
        "\n",
        "\n",
        "def compute_mean_audio_features(tracks_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute the mean audio features for tracks of the same artist.\n",
        "\n",
        "    :param tracks_df: tracks dataframe (with audio features per each track).\n",
        "    :return: artist dataframe (with mean audio features per each artist).\n",
        "    \"\"\"\n",
        "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
        "    columns = ['Name', 'ID', 'Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo']\n",
        "    keep = {}\n",
        "    total = []\n",
        "\n",
        "    for index, row in tracks_df.iterrows():\n",
        "      key = row['Artist Name']+','+row['Artist ID']\n",
        "      if key not in keep.keys():\n",
        "          keep[key] = [[row['Danceability'], row['Energy'], row['Loudness'], row['Speechiness'], row['Acousticness'], row['Instrumentalness'], row['Liveness'], row['Valence'], row['Tempo']]]\n",
        "      else:\n",
        "          keep[key].append([row['Danceability'], row['Energy'], row['Loudness'], row['Speechiness'], row['Acousticness'], row['Instrumentalness'], row['Liveness'], row['Valence'], row['Tempo']])\n",
        "\n",
        "    for key in keep.keys():\n",
        "      name, id = key.split(',')\n",
        "      info = [name, id] + ((np.array(keep[key]).sum(axis=0))/len(keep[key])).tolist()\n",
        "      total.append(info)\n",
        "    \n",
        "    table = pd.DataFrame(total, columns=columns)\n",
        "    return table\n",
        "    # ----------------- END OF FUNCTION --------------------- #\n",
        "\n",
        "\n",
        "def create_similarity_graph(artist_audio_features_df: pd.DataFrame, similarity: str, out_filename: str = None) -> \\\n",
        "        nx.Graph:\n",
        "    \"\"\"\n",
        "    Create a similarity graph from a dataframe with mean audio features per artist.\n",
        "\n",
        "    :param artist_audio_features_df: dataframe with mean audio features per artist.\n",
        "    :param similarity: the name of the similarity metric to use (e.g. \"cosine\" or \"euclidean\").\n",
        "    :param out_filename: name of the file that will be saved.\n",
        "    :return: a networkx graph with the similarity between artists as edge weights.\n",
        "    \"\"\"\n",
        "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
        "    complete = nx.Graph()\n",
        "\n",
        "    for index, row in artist_audio_features_df.iterrows():\n",
        "      complete.add_node(row['Name'], \n",
        "                    id = row['ID'], \n",
        "                    features = [row['Danceability'], row['Energy'], row['Loudness'], row['Speechiness'], row['Acousticness'], row['Instrumentalness'], row['Liveness'], row['Valence'], row['Tempo']])\n",
        "\n",
        "    complete.add_edges_from(itertools.combinations(complete, 2))\n",
        "\n",
        "    for ins,out,weight in complete.edges(data=True):\n",
        "      features_in = np.array(dict(complete.nodes())[ins]['features'])  \n",
        "      features_out = np.array(dict(complete.nodes())[out]['features']) \n",
        "\n",
        "      if similarity=='euclidean':\n",
        "        dist = np.linalg.norm(features_in-features_out)\n",
        "      elif similarity=='cosine':\n",
        "        dist = dot(features_in, features_out)/(norm(features_in)*norm(features_out))\n",
        "      \n",
        "      weight['weight'] = dist \n",
        "    \n",
        "    for node in list(complete.nodes()):\n",
        "      del dict(complete.nodes())[node]['features']\n",
        "\n",
        "    nx.write_graphml(complete, out_filename+\".graphml\")\n",
        "    return complete  \n",
        "    # ----------------- END OF FUNCTION --------------------- #\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ------- IMPLEMENT HERE THE MAIN FOR THIS SESSION ------- #\n",
        "    pass\n",
        "    # ------------------- END OF MAIN ------------------------ #\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dTJPWemnuEf"
      },
      "source": [
        "###Work zone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cVdJeFUZ9mMR"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m gB \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mread_graphml(\u001b[39m'\u001b[39m\u001b[39mgB.graphml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m gD \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mread_graphml(\u001b[39m'\u001b[39m\u001b[39mgD.graphml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m D \u001b[39m=\u001b[39m  pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mD.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniforge3/envs/spotify/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/miniforge3/envs/spotify/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/miniforge3/envs/spotify/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/miniforge3/envs/spotify/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/miniforge3/envs/spotify/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D.csv'"
          ]
        }
      ],
      "source": [
        "gB = nx.read_graphml('gB.graphml')\n",
        "gD = nx.read_graphml('gD.graphml')\n",
        "D =  pd.read_csv(\"data_sesion-1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "gM88pMFS9ucl"
      },
      "outputs": [],
      "source": [
        "#Exercise 1\n",
        "gB_prime = retrieve_bidirectional_edges(gB, 'gB_bi')\n",
        "gD_prime = retrieve_bidirectional_edges(gD, 'gD_bi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "0VP-9wmP-CcH"
      },
      "outputs": [],
      "source": [
        "#Exercise 2\n",
        "mean_audio = compute_mean_audio_features(D) #We would need separated datasets? One for gB and one for gD?\n",
        "similarity_graph = create_similarity_graph(mean_audio, 'euclidean', 'similarity_graph')\n",
        "similarity_graph_gB = prune_low_weight_edges(similarity_graph, min_weight=28.5, out_filename='similarity_graph')\n",
        "similarity_graph_gD = prune_low_weight_edges(similarity_graph, min_weight=24, out_filename='similarity_graph')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d80vRo-8_ZNU",
        "outputId": "ae736e90-785c-4dd8-88c8-1f40e0af22bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gB_prime.size() - similarity_graph_gB.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXNclp_f_bgZ",
        "outputId": "2c6da7ba-06e0-4f6f-9a51-cfa22f0a551c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-22"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gD_prime.size() - similarity_graph_gD.size()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2CNIp1QlN_EG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
